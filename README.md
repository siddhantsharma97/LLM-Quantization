# LLM-Quantization
Quantization of Qwen/Qwen1.5-1.8B-Chat model to 4-bit GGUF format using Llama-cpp module
